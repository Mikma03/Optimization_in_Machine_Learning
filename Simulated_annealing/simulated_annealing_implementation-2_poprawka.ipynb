{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zostanie pokazane, jak można wdrożyć optymalizację symulowanego wyżarzania. \n",
    "\n",
    "Najpierw musimy zdefiniować naszą funkcję celu i granice kazdej zmiennej wejściowej do funkcji celu. \n",
    "\n",
    "Funkcja celu to tylko funkcja Pythona, którą będziemy nazywali  `objective()`. Granice będą tablicą 2D z jednym wymiarem dla każdej zmiennej wejściowej, który definiuje minimum i maksimum dla zmiennej. \n",
    "\n",
    "Na przykład jednowymiarowa funkcja celu i granice mozna zdefiniowac w nastepujacy sposób:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import niezbednych bibliotek\n",
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "from numpy import arange\n",
    "from numpy.random import seed\n",
    "from numpy import asarray\n",
    "from numpy import exp\n",
    "from numpy.random import randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['NFT', 'NFTsMarketplace', 'NFTExchange', 'NFTgiveaway', 'NFTMarketplace', 'NFTmarket', 'NFTArt_Finance', 'OpenSeaNFT' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "    return 0\n",
    "# define range for input\n",
    "bounds = np.asarray([[-5.0, 5.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie możemy wygenerować nasz punkt początkowy jako punkt losowy w granicach problemu,\n",
    "kolejno można ocenic to za pomocą funkcji celu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an initial point\n",
    "best = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "# evaluate the initial point\n",
    "best_eval = objective(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Musimy zachować „aktualne” rozwiązanie, na którym koncentruje się wyszukiwanie i które może być\n",
    "zastąpione lepszymi rozwiązaniami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current working solution\n",
    "curr, curr_eval = best, best_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz możemy zapętlić predefiniowaną liczbę iteracji algorytmu zdefiniowanego jako `n_iterations`, np. 100 lub 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_iterations):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwszym krokiem iteracji algorytmu jest wygenerowanie nowego kandydata na rozwiązanie z obecnego\n",
    "dzialajacego rozwiazania, np. zrob nastepny krok. Wymaga to wstępnie zdefiniowanego parametru `step_size`, który:\n",
    "odnosi się do granic przestrzeni wyszukiwania. \n",
    "\n",
    "Zrobimy losowy krok z rozkladem Gaussa gdzie średnia jest naszym aktualnym punktem, a odchylenie standardowe jest określone przez\n",
    "`“step_size`. \n",
    "\n",
    "Oznacza to, że około 99 procent podjętych kroków będzie mieściło się w 3 * step_size aktualnego punktu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = solution + randn(len(bounds)) * step_siz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie musimy w ten sposób podejmować kroków. Możemy chcieć użyć równomiernego rozkładu między 0 a rozmiar kroku. \n",
    "\n",
    "Na przykład:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = solution + rand(len(bounds)) * step_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie musimy to ocenić."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_eval = objective(candidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie musimy sprawdzić, czy ocena tego nowego punktu jest tak dobra lub lepsza niż aktualna\n",
    "najlepszy punkt. Jeśli tak jest to zastąpić nasz obecny najlepszy punkt tym nowym punktem. \n",
    "\n",
    "To jest oddzielone od aktualnie dzialajacego rozwiazania, które jest przedmiotem poszukiwań."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if candidate_eval < best_eval:\n",
    "    # store new best point\n",
    "    best, best_eval = candidate, candidate_eval\n",
    "    # report progress\n",
    "    print('>%d f(%s) = %.5f' % (i, best, best_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie musimy przygotować się do wymiany obecnego działającego rozwiązania. \n",
    "\n",
    "Pierwszym krokiem jest obliczenie różnicy między oceną funkcji celu obecnego rozwiązania a obecnym dzialajacym rozwiazaniem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = candidate_eval - curr_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie musimy obliczyć aktualną temperaturę, korzystając z harmonogramu szybkiego wyżarzania, gdzie `temp` to początkowa temperatura podana jako argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = temp / float(i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy wtedy obliczyć prawdopodobieństwo zaakceptowania rozwiązania o gorszej wydajności niż nasze obecne dzialajace rozwiazanie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metropolis = exp(-diff / t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wreszcie możemy zaakceptować nowy punkt jako obecnie dzialajace rozwiązanie, jeśli ma lepszą ocenę fukcji celu (różnica jest ujemna) lub jeśli funkcja celu jest gorsza, ale my prawdopodobnie zdecydujemy się to zaakceptować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if diff < 0 or rand() < metropolis:\n",
    "    # store the new current point\n",
    "    curr, curr_eval = candidate, candidate_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy zaimplementować ten symulowany algorytm wyżarzania jako funkcję wielokrotnego użytku, która przyjmuje nazwę jako funkcję celu, granice każdej zmiennej wejściowej, suma iteracji, wielkość kroku i zwraca najlepsze znalezione rozwiązanie i jego ocenę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing(objective, bounds, n_iterations, step_size, temp):\n",
    "\t# generate an initial point\n",
    "\tbest = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "\t# evaluate the initial point\n",
    "\tbest_eval = objective(best)\n",
    "\t# current working solution\n",
    "\tcurr, curr_eval = best, best_eval\n",
    "\t# run the algorithm\n",
    "\tfor i in range(n_iterations):\n",
    "\t\t# take a step\n",
    "\t\tcandidate = curr + randn(len(bounds)) * step_size\n",
    "\t\t# evaluate candidate point\n",
    "\t\tcandidate_eval = objective(candidate)\n",
    "\t\t# check for new best solution\n",
    "\t\tif candidate_eval < best_eval:\n",
    "\t\t\t# store new best point\n",
    "\t\t\tbest, best_eval = candidate, candidate_eval\n",
    "\t\t\t# report progress\n",
    "\t\t\tprint('>%d f(%s) = %.5f' % (i, best, best_eval))\n",
    "\t\t# difference between candidate and current point evaluation\n",
    "\t\tdiff = candidate_eval - curr_eval\n",
    "\t\t# calculate temperature for current epoch\n",
    "\t\tt = temp / float(i + 1)\n",
    "\t\t# calculate metropolis acceptance criterion\n",
    "\t\tmetropolis = exp(-diff / t)\n",
    "\t\t# check if we should keep the new point\n",
    "\t\tif diff < 0 or rand() < metropolis:\n",
    "\t\t\t# store the new current point\n",
    "\t\t\tcurr, curr_eval = candidate, candidate_eval\n",
    "\treturn [best, best_eval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższy przykład definiuje funkcję, a następnie tworzy wykres liniowy powierzchni odpowiedzi funkcji dla siatki wartości wejściowych i oznacza optima przy f(0,0) = 0,0 z czerwoną linią."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# objective function\n",
    "def objective(x):\n",
    "\treturn x[0]**2.0\n",
    "\n",
    "# define range for input\n",
    "r_min, r_max = -5.0, 5.0\n",
    "# sample input range uniformly at 0.1 increments\n",
    "inputs = arange(r_min, r_max, 0.1)\n",
    "# compute targets\n",
    "results = [objective([x]) for x in inputs]\n",
    "# create a line plot of input vs result\n",
    "pyplot.plot(inputs, results)\n",
    "# define optimal input value\n",
    "x_optima = 0.0\n",
    "# draw a vertical line at the optimal input\n",
    "pyplot.axvline(x=x_optima, ls='--', color='red')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zanim zastosujemy algorytm optymalizacji do problemu, poświęćmy chwilę, aby trochę lepiej zrozumieć kryterium akceptacji. Po pierwsze, harmonogram szybkiego wyżarzania to wykładnicza funkcja liczby iteracji. \n",
    "\n",
    "Możemy to wyjaśnić tworząc wykres temperatury dla każdej iteracji algorytmu. Użyjemy temperatury początkowej 10 i 100 iteracji algorytmu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruchomienie przykładu oblicza temperaturę dla każdej iteracji algorytmu i tworzy wykres iteracji algorytmu (oś x) w funkcji temperatury (oś y). \n",
    "\n",
    "Widzimy, że temperatura spada szybko - wykładniczo, nie liniowo, po 20 iteracjach jest poniżej 1 i pozostaje niska przez pozostałą część wyszukiwania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore temperature vs algorithm iteration for simulated annealing\n",
    "from matplotlib import pyplot\n",
    "# total iterations of algorithm\n",
    "iterations = 100\n",
    "# initial temperature\n",
    "initial_temp = 10\n",
    "# array of iterations from 0 to iterations - 1\n",
    "iterations = [i for i in range(iterations)]\n",
    "# temperatures for each iterations\n",
    "temperatures = [initial_temp/float(i + 1) for i in iterations]\n",
    "# plot iterations vs temperatures\n",
    "pyplot.plot(iterations, temperatures)\n",
    "pyplot.xlabel('Iteration')\n",
    "pyplot.ylabel('Temperature')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przypomnijmy, że kryterium jest funkcją temperatury, ale jest nim również funkcja tego, jak różni się obiektywna ocena nowego punktu w porównaniu z obecnie dzialajacym rozwiązaniem. \n",
    "\n",
    "W związku z tym wykreślimy kryterium dla kilku różnych „różnic w celu” wartość funkcji”, aby zobaczyć wpływ, jaki ma to na prawdopodobieństwo akceptacji. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruchomienie przykładu oblicza kryterium akceptacji dla każdej iteracji algorytmu używając temperatury pokazanej dla każdej iteracji. \n",
    "\n",
    "Działka ma trzy wiersze dla trzech różnic między nowym, gorszym rozwiązaniem a rozwiązaniem obecnie działającym. Widzimy, że im gorsze rozwiązanie (im większa różnica), tym mniejsze prawdopodobieństwo modelu na zaakceptowanie gorszego rozwiązania, niezależnie od iteracji algorytmu, jak możnaby się spodziewać. \n",
    "\n",
    "Możemy zobaczyć też, że we wszystkich przypadkach prawdopodobieństwo zaakceptowania gorszych rozwiązań maleje wraz z iteracją algorytmu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore metropolis acceptance criterion for simulated annealing\n",
    "from math import exp\n",
    "from matplotlib import pyplot\n",
    "# total iterations of algorithm\n",
    "iterations = 100\n",
    "# initial temperature\n",
    "initial_temp = 10\n",
    "# array of iterations from 0 to iterations - 1\n",
    "iterations = [i for i in range(iterations)]\n",
    "# temperatures for each iterations\n",
    "temperatures = [initial_temp/float(i + 1) for i in iterations]\n",
    "# metropolis acceptance criterion\n",
    "differences = [0.01, 0.1, 1.0]\n",
    "for d in differences:\n",
    "\tmetropolis = [exp(-d/t) for t in temperatures]\n",
    "\t# plot iterations vs metropolis\n",
    "\tlabel = 'diff=%.2f' % d\n",
    "\tpyplot.plot(iterations, metropolis, label=label)\n",
    "# inalize plot\n",
    "pyplot.xlabel('Iteration')\n",
    "pyplot.ylabel('Metropolis Criterion')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw zainicjujemy generator liczb pseudolosowych. Generalnie nie jest to wymagane, ale w tym przypadku zapewni, że z każdym biegiem otrzymamy te same wyniki (taką samą sekwencję liczb losowych) algorytmu, abyśmy mogli później wykreślić wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function\n",
    "def objective(x):\n",
    "\treturn x[0]**2.0\n",
    "\n",
    "# simulated annealing algorithm\n",
    "def simulated_annealing(objective, bounds, n_iterations, step_size, temp):\n",
    "\t# generate an initial point\n",
    "\tbest = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "\t# evaluate the initial point\n",
    "\tbest_eval = objective(best)\n",
    "\t# current working solution\n",
    "\tcurr, curr_eval = best, best_eval\n",
    "\tscores = list()\n",
    "\t# run the algorithm\n",
    "\tfor i in range(n_iterations):\n",
    "\t\t# take a step\n",
    "\t\tcandidate = curr + randn(len(bounds)) * step_size\n",
    "\t\t# evaluate candidate point\n",
    "\t\tcandidate_eval = objective(candidate)\n",
    "\t\t# check for new best solution\n",
    "\t\tif candidate_eval < best_eval:\n",
    "\t\t\t# store new best point\n",
    "\t\t\tbest, best_eval = candidate, candidate_eval\n",
    "\t\t\t# keep track of scores\n",
    "\t\t\tscores.append(best_eval)\n",
    "\t\t\t# report progress\n",
    "\t\t\tprint('>%d f(%s) = %.5f' % (i, best, best_eval))\n",
    "\t\t# difference between candidate and current point evaluation\n",
    "\t\tdiff = candidate_eval - curr_eval\n",
    "\t\t# calculate temperature for current epoch\n",
    "\t\tt = temp / float(i + 1)\n",
    "\t\t# calculate metropolis acceptance criterion\n",
    "\t\tmetropolis = exp(-diff / t)\n",
    "\t\t# check if we should keep the new point\n",
    "\t\tif diff < 0 or rand() < metropolis:\n",
    "\t\t\t# store the new current point\n",
    "\t\t\tcurr, curr_eval = candidate, candidate_eval\n",
    "\treturn [best, best_eval, scores]\n",
    "\n",
    "# seed the pseudorandom number generator\n",
    "seed(1)\n",
    "# define range for input\n",
    "bounds = asarray([[-5.0, 5.0]])\n",
    "# define the total iterations\n",
    "n_iterations = 1000\n",
    "# define the maximum step size\n",
    "step_size = 0.1\n",
    "# initial temperature\n",
    "temp = 10\n",
    "# perform the simulated annealing search\n",
    "best, score, scores = simulated_annealing(objective, bounds, n_iterations, step_size, temp)\n",
    "print('Done!')\n",
    "print('f(%s) = %f' % (best, score))\n",
    "# line plot of best scores\n",
    "pyplot.plot(scores, '.-')\n",
    "pyplot.xlabel('Improvement Number')\n",
    "pyplot.ylabel('Evaluation f(x)')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruchomienie przykładu pokazuje postęp wyszukiwania, w tym numer iteracji, dane wejściowe do funkcji i odpowiedź funkcji celu za każdym razem, gdy następuje wykryta poprawa. Po zakończeniu wyszukiwania zostaje znalezione najlepsze rozwiązanie i raportowana jest jego ocena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesujące może być przejrzenie postępu wyszukiwania w postaci wykresu liniowego, który pokazuje zmianę oceny najlepszego rozwiązania za każdym razem, gdy następuje poprawa. \n",
    "\n",
    "Podczas wyszukiwania widzimy około 20 zmian w ocenie funkcji celu za pomocą dużych zmian początkowo i bardzo małych (do niezauważalnych) zmian pod koniec wyszukiwania, algorytm zbiegł się w optimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb659e5826d19a9d4dbdce5e8e106959bbf6ebf861dfcc7aacf5227571a6f1d4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
